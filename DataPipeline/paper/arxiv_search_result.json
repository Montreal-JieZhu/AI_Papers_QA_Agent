[
  {
    "title": "SceneGen: Single-Image 3D Scene Generation in One Feedforward Pass",
    "abs_url": "https://arxiv.org/abs/2508.15769",
    "pdf_url": "https://arxiv.org/pdf/2508.15769",
    "authors": [
      "Yanxu Meng",
      "Haoning Wu",
      "Ya Zhang",
      "Weidi Xie"
    ],
    "abstract": "3D content generation has recently attracted significant research interest due to its applications in VR/AR and embodied AI. In this work, we address the challenging task of synthesizing multiple 3D assets within a single scene image. Concretely, our contributions are fourfold: (i) we present SceneGen, a novel framework that takes a scene image and corresponding object masks as input, simultaneously producing multiple 3D assets with geometry and texture. Notably, SceneGen operates with no need for optimization or asset retrieval; (ii) we introduce a novel feature aggregation module that integrates local and global scene information from visual and geometric encoders within the feature extraction module. Coupled with a position head, this enables the generation of 3D assets and their relative spatial positions in a single feedforward pass; (iii) we demonstrate SceneGen's direct extensibility to multi-image input scenarios. Despite being trained solely on single-image inputs, our architectural design enables improved generation performance with multi-image inputs; and (iv) extensive quantitative and qualitative evaluations confirm the efficiency and robust generation abilities of our approach. We believe this paradigm offers a novel solution for high-quality 3D content generation, potentially advancing its practical applications in downstream tasks. The code and model will be publicly available at: https://mengmouxu.github.io/SceneGen.△ Less",
    "submitted_date_raw": "Submitted 21 August, 2025; originally announced August 2025.",
    "identity_key": "2508.15769"
  },
  {
    "title": "Discovering Hidden Algebraic Structures via Transformers with Rank-Aware Beam GRPO",
    "abs_url": "https://arxiv.org/abs/2508.15766",
    "pdf_url": "https://arxiv.org/pdf/2508.15766",
    "authors": [
      "Jaeha Lee",
      "Gio Huh",
      "Ning Su",
      "Tony Yue YU"
    ],
    "abstract": "Recent efforts have extended the capabilities of transformers in logical reasoning and symbolic computations. In this work, we investigate their capacity for non-linear latent pattern discovery in the context of functional decomposition, focusing on the challenging algebraic task of multivariate polynomial decomposition. This problem, with widespread applications in science and engineering, is proved to be NP-hard, and demands both precision and insight. Our contributions are threefold: First, we develop a synthetic data generation pipeline providing fine-grained control over problem complexity. Second, we train transformer models via supervised learning and evaluate them across four key dimensions involving scaling behavior and generalizability. Third, we propose Beam Grouped Relative Policy Optimization (BGRPO), a rank-aware reinforcement learning method suitable for hard algebraic problems. Finetuning with BGRPO improves accuracy while reducing beam width by up to half, resulting in approximately 75% lower inference compute. Additionally, our model demonstrates competitive performance in polynomial simplification, outperforming Mathematica in various cases.△ Less",
    "submitted_date_raw": "Submitted 21 August, 2025; originally announced August 2025.",
    "identity_key": "2508.15766"
  },
  {
    "title": "LiveMCP-101: Stress Testing and Diagnosing MCP-enabled Agents on Challenging Queries",
    "abs_url": "https://arxiv.org/abs/2508.15760",
    "pdf_url": "https://arxiv.org/pdf/2508.15760",
    "authors": [
      "Ming Yin",
      "Dinghan Shen",
      "Silei Xu",
      "Jianbing Han",
      "Sixun Dong",
      "Mian Zhang",
      "Yebowen Hu",
      "Shujian Liu",
      "Simin Ma",
      "Song Wang",
      "Sathish Reddy Indurthi",
      "Xun Wang",
      "Yiran Chen",
      "Kaiqiang Song"
    ],
    "abstract": "Tool calling has emerged as a critical capability for AI agents to interact with the real world and solve complex tasks. While the Model Context Protocol (MCP) provides a powerful standardized framework for tool integration, there is a significant gap in benchmarking how well AI agents can effectively solve multi-step tasks using diverse MCP tools in realistic, dynamic scenarios. In this work, we present LiveMCP-101, a benchmark of 101 carefully curated real-world queries, refined through iterative LLM rewriting and manual review, that require coordinated use of multiple MCP tools including web search, file operations, mathematical reasoning, and data analysis. Moreover, we introduce a novel evaluation approach that leverages ground-truth execution plans rather than raw API outputs, better reflecting the evolving nature of real-world environments. Experiments show that even frontier LLMs achieve a success rate below 60\\%, highlighting major challenges in tool orchestration. Detailed ablations and error analysis further reveal distinct failure modes and inefficiencies in token usage, pointing to concrete directions for advancing current models. LiveMCP-101 sets a rigorous standard for evaluating real-world agent capabilities, advancing toward autonomous AI systems that reliably execute complex tasks through tool use.△ Less",
    "submitted_date_raw": "Submitted 21 August, 2025; originally announced August 2025.",
    "identity_key": "2508.15760"
  },
  {
    "title": "Language-Guided Tuning: Enhancing Numeric Optimization with Textual Feedback",
    "abs_url": "https://arxiv.org/abs/2508.15757",
    "pdf_url": "https://arxiv.org/pdf/2508.15757",
    "authors": [
      "Yuxing Lu",
      "Yucheng Hu",
      "Nan Sun",
      "Xukai Zhao"
    ],
    "abstract": "Configuration optimization remains a critical bottleneck in machine learning, requiring coordinated tuning across model architecture, training strategy, feature engineering, and hyperparameters. Traditional approaches treat these dimensions independently and lack interpretability, while recent automated methods struggle with dynamic adaptability and semantic reasoning about optimization decisions. We introduce Language-Guided Tuning (LGT), a novel framework that employs multi-agent Large Language Models to intelligently optimize configurations through natural language reasoning. We apply textual gradients - qualitative feedback signals that complement numerical optimization by providing semantic understanding of training dynamics and configuration interdependencies. LGT coordinates three specialized agents: an Advisor that proposes configuration changes, an Evaluator that assesses progress, and an Optimizer that refines the decision-making process, creating a self-improving feedback loop. Through comprehensive evaluation on six diverse datasets, LGT demonstrates substantial improvements over traditional optimization methods, achieving performance gains while maintaining high interpretability.△ Less",
    "submitted_date_raw": "Submitted 21 August, 2025; originally announced August 2025.",
    "identity_key": "2508.15757"
  },
  {
    "title": "Neural Robot Dynamics",
    "abs_url": "https://arxiv.org/abs/2508.15755",
    "pdf_url": "https://arxiv.org/pdf/2508.15755",
    "authors": [
      "Jie Xu",
      "Eric Heiden",
      "Iretiayo Akinola",
      "Dieter Fox",
      "Miles Macklin",
      "Yashraj Narang"
    ],
    "abstract": "Accurate and efficient simulation of modern robots remains challenging due to their high degrees of freedom and intricate mechanisms. Neural simulators have emerged as a promising alternative to traditional analytical simulators, capable of efficiently predicting complex dynamics and adapting to real-world data; however, existing neural simulators typically require application-specific training and fail to generalize to novel tasks and/or environments, primarily due to inadequate representations of the global state. In this work, we address the problem of learning generalizable neural simulators for robots that are structured as articulated rigid bodies. We propose NeRD (Neural Robot Dynamics), learned robot-specific dynamics models for predicting future states for articulated rigid bodies under contact constraints. NeRD uniquely replaces the low-level dynamics and contact solvers in an analytical simulator and employs a robot-centric and spatially-invariant simulation state representation. We integrate the learned NeRD models as an interchangeable backend solver within a state-of-the-art robotics simulator. We conduct extensive experiments to show that the NeRD simulators are stable and accurate over a thousand simulation steps; generalize across tasks and environment configurations; enable policy learning exclusively in a neural engine; and, unlike most classical simulators, can be fine-tuned from real-world data to bridge the gap between simulation and reality.△ Less",
    "submitted_date_raw": "Submitted 21 August, 2025; originally announced August 2025.",
    "identity_key": "2508.15755"
  },
  {
    "title": "Dissecting Tool-Integrated Reasoning: An Empirical Study and Analysis",
    "abs_url": "https://arxiv.org/abs/2508.15754",
    "pdf_url": "https://arxiv.org/pdf/2508.15754",
    "authors": [
      "Yufeng Zhao",
      "Junnan Liu",
      "Hongwei Liu",
      "Dongsheng Zhu",
      "Yuan Shen",
      "Songyang Zhang",
      "Kai Chen"
    ],
    "abstract": "Large Language Models (LLMs) have made significant strides in reasoning tasks through methods like chain-of-thought (CoT) reasoning. However, they often fall short in tasks requiring precise computations. Tool-Integrated Reasoning (TIR) has emerged as a solution by incorporating external tools into the reasoning process. Nevertheless, the generalization of TIR in improving the reasoning ability of LLM is still unclear. Additionally, whether TIR has improved the model's reasoning behavior and helped the model think remains to be studied. We introduce ReasonZoo, a comprehensive benchmark encompassing nine diverse reasoning categories, to evaluate the effectiveness of TIR across various domains. Additionally, we propose two novel metrics, Performance-Aware Cost (PAC) and Area Under the Performance-Cost Curve (AUC-PCC), to assess reasoning efficiency. Our empirical evaluation demonstrates that TIR-enabled models consistently outperform their non-TIR counterparts in both mathematical and non-mathematical tasks. Furthermore, TIR enhances reasoning efficiency, as evidenced by improved PAC and AUC-PCC, indicating reduced overthinking and more streamlined reasoning. These findings underscore the domain-general benefits of TIR and its potential to advance LLM capabilities in complex reasoning tasks.△ Less",
    "submitted_date_raw": "Submitted 21 August, 2025; originally announced August 2025.",
    "identity_key": "2508.15754"
  },
  {
    "title": "\"Does the cafe entrance look accessible? Where is the door?\" Towards Geospatial AI Agents for Visual Inquiries",
    "abs_url": "https://arxiv.org/abs/2508.15752",
    "pdf_url": "https://arxiv.org/pdf/2508.15752",
    "authors": [
      "Jon E. Froehlich",
      "Jared Hwang",
      "Zeyu Wang",
      "John S. O'Meara",
      "Xia Su",
      "William Huang",
      "Yang Zhang",
      "Alex Fiannaca",
      "Philip Nelson",
      "Shaun Kane"
    ],
    "abstract": "Interactive digital maps have revolutionized how people travel and learn about the world; however, they rely on pre-existing structured data in GIS databases (e.g., road networks, POI indices), limiting their ability to address geo-visual questions related to what the world looks like. We introduce our vision for Geo-Visual Agents--multimodal AI agents capable of understanding and responding to nuanced visual-spatial inquiries about the world by analyzing large-scale repositories of geospatial images, including streetscapes (e.g., Google Street View), place-based photos (e.g., TripAdvisor, Yelp), and aerial imagery (e.g., satellite photos) combined with traditional GIS data sources. We define our vision, describe sensing and interaction approaches, provide three exemplars, and enumerate key challenges and opportunities for future work.△ Less",
    "submitted_date_raw": "Submitted 21 August, 2025; originally announced August 2025.",
    "identity_key": "2508.15752"
  },
  {
    "title": "Response and Prompt Evaluation to Prevent Parasocial Relationships with Chatbots",
    "abs_url": "https://arxiv.org/abs/2508.15748",
    "pdf_url": "https://arxiv.org/pdf/2508.15748",
    "authors": [
      "Emma Rath",
      "Stuart Armstrong",
      "Rebecca Gorman"
    ],
    "abstract": "The development of parasocial relationships with AI agents has severe, and in some cases, tragic effects for human well-being. Yet preventing such dynamics is challenging: parasocial cues often emerge gradually in private conversations, and not all forms of emotional engagement are inherently harmful. We address this challenge by introducing a simple response evaluation framework, created by repurposing a state-of-the-art language model, that evaluates ongoing conversations for parasocial cues in real time. To test the feasibility of this approach, we constructed a small synthetic dataset of thirty dialogues spanning parasocial, sycophantic, and neutral conversations. Iterative evaluation with five stage testing successfully identified all parasocial conversations while avoiding false positives under a tolerant unanimity rule, with detection typically occurring within the first few exchanges. These findings provide preliminary evidence that evaluation agents can provide a viable solution for the prevention of parasocial relations.△ Less",
    "submitted_date_raw": "Submitted 21 August, 2025; originally announced August 2025.",
    "identity_key": "2508.15748"
  },
  {
    "title": "End-to-End Agentic RAG System Training for Traceable Diagnostic Reasoning",
    "abs_url": "https://arxiv.org/abs/2508.15746",
    "pdf_url": "https://arxiv.org/pdf/2508.15746",
    "authors": [
      "Qiaoyu Zheng",
      "Yuze Sun",
      "Chaoyi Wu",
      "Weike Zhao",
      "Pengcheng Qiu",
      "Yongguo Yu",
      "Kun Sun",
      "Yanfeng Wang",
      "Ya Zhang",
      "Weidi Xie"
    ],
    "abstract": "Accurate diagnosis with medical large language models is hindered by knowledge gaps and hallucinations. Retrieval and tool-augmented methods help, but their impact is limited by weak use of external knowledge and poor feedback-reasoning traceability. To address these challenges, We introduce Deep-DxSearch, an agentic RAG system trained end-to-end with reinforcement learning (RL) that enables steer tracebale retrieval-augmented reasoning for medical diagnosis. In Deep-DxSearch, we first construct a large-scale medical retrieval corpus comprising patient records and reliable medical knowledge sources to support retrieval-aware reasoning across diagnostic scenarios. More crutially, we frame the LLM as the core agent and the retrieval corpus as its environment, using tailored rewards on format, retrieval, reasoning structure, and diagnostic accuracy, thereby evolving the agentic RAG policy from large-scale data through RL.\n  Experiments demonstrate that our end-to-end agentic RL training framework consistently outperforms prompt-engineering and training-free RAG approaches across multiple data centers. After training, Deep-DxSearch achieves substantial gains in diagnostic accuracy, surpassing strong diagnostic baselines such as GPT-4o, DeepSeek-R1, and other medical-specific frameworks for both common and rare disease diagnosis under in-distribution and out-of-distribution settings. Moreover, ablation studies on reward design and retrieval corpus components confirm their critical roles, underscoring the uniqueness and effectiveness of our approach compared with traditional implementations. Finally, case studies and interpretability analyses highlight improvements in Deep-DxSearch's diagnostic policy, providing deeper insight into its performance gains and supporting clinicians in delivering more reliable and precise preliminary diagnoses. See https://github.com/MAGIC-AI4Med/Deep-DxSearch.△ Less",
    "submitted_date_raw": "Submitted 21 August, 2025; originally announced August 2025.",
    "identity_key": "2508.15746"
  },
  {
    "title": "Measuring the environmental impact of delivering AI at Google Scale",
    "abs_url": "https://arxiv.org/abs/2508.15734",
    "pdf_url": "https://arxiv.org/pdf/2508.15734",
    "authors": [
      "Cooper Elsworth",
      "Keguo Huang",
      "David Patterson",
      "Ian Schneider",
      "Robert Sedivy",
      "Savannah Goodman",
      "Ben Townsend",
      "Parthasarathy Ranganathan",
      "Jeff Dean",
      "Amin Vahdat",
      "Ben Gomes",
      "James Manyika"
    ],
    "abstract": "The transformative power of AI is undeniable - but as user adoption accelerates, so does the need to understand and mitigate the environmental impact of AI serving. However, no studies have measured AI serving environmental metrics in a production environment. This paper addresses this gap by proposing and executing a comprehensive methodology for measuring the energy usage, carbon emissions, and water consumption of AI inference workloads in a large-scale, AI production environment. Our approach accounts for the full stack of AI serving infrastructure - including active AI accelerator power, host system energy, idle machine capacity, and data center energy overhead. Through detailed instrumentation of Google's AI infrastructure for serving the Gemini AI assistant, we find the median Gemini Apps text prompt consumes 0.24 Wh of energy - a figure substantially lower than many public estimates. We also show that Google's software efficiency efforts and clean energy procurement have driven a 33x reduction in energy consumption and a 44x reduction in carbon footprint for the median Gemini Apps text prompt over one year. We identify that the median Gemini Apps text prompt uses less energy than watching nine seconds of television (0.24 Wh) and consumes the equivalent of five drops of water (0.26 mL). While these impacts are low compared to other daily activities, reducing the environmental impact of AI serving continues to warrant important attention. Towards this objective, we propose that a comprehensive measurement of AI serving environmental metrics is critical for accurately comparing models, and to properly incentivize efficiency gains across the full AI serving stack.△ Less",
    "submitted_date_raw": "Submitted 21 August, 2025; originally announced August 2025.",
    "identity_key": "2508.15734"
  },
  {
    "title": "Numerical models outperform AI weather forecasts of record-breaking extremes",
    "abs_url": "https://arxiv.org/abs/2508.15724",
    "pdf_url": "https://arxiv.org/pdf/2508.15724",
    "authors": [
      "Zhongwei Zhang",
      "Erich Fischer",
      "Jakob Zscheischler",
      "Sebastian Engelke"
    ],
    "abstract": "Artificial intelligence (AI)-based models are revolutionizing weather forecasting and have surpassed leading numerical weather prediction systems on various benchmark tasks. However, their ability to extrapolate and reliably forecast unprecedented extreme events remains unclear. Here, we show that for record-breaking weather extremes, the numerical model High RESolution forecast (HRES) from the European Centre for Medium-Range Weather Forecasts still consistently outperforms state-of-the-art AI models GraphCast, GraphCast operational, Pangu-Weather, Pangu-Weather operational, and Fuxi. We demonstrate that forecast errors in AI models are consistently larger for record-breaking heat, cold, and wind than in HRES across nearly all lead times. We further find that the examined AI models tend to underestimate both the frequency and intensity of record-breaking events, and they underpredict hot records and overestimate cold records with growing errors for larger record exceedance. Our findings underscore the current limitations of AI weather models in extrapolating beyond their training domain and in forecasting the potentially most impactful record-breaking weather events that are particularly frequent in a rapidly warming climate. Further rigorous verification and model development is needed before these models can be solely relied upon for high-stakes applications such as early warning systems and disaster management.△ Less",
    "submitted_date_raw": "Submitted 21 August, 2025; originally announced August 2025.",
    "identity_key": "2508.15724"
  },
  {
    "title": "EcomMMMU: Strategic Utilization of Visuals for Robust Multimodal E-Commerce Models",
    "abs_url": "https://arxiv.org/abs/2508.15721",
    "pdf_url": "https://arxiv.org/pdf/2508.15721",
    "authors": [
      "Xinyi Ling",
      "Hanwen Du",
      "Zhihui Zhu",
      "Xia Ning"
    ],
    "abstract": "E-commerce platforms are rich in multimodal data, featuring a variety of images that depict product details. However, this raises an important question: do these images always enhance product understanding, or can they sometimes introduce redundancy or degrade performance? Existing datasets are limited in both scale and design, making it difficult to systematically examine this question. To this end, we introduce EcomMMMU, an e-commerce multimodal multitask understanding dataset with 406,190 samples and 8,989,510 images. EcomMMMU is comprised of multi-image visual-language data designed with 8 essential tasks and a specialized VSS subset to benchmark the capability of multimodal large language models (MLLMs) to effectively utilize visual content. Analysis on EcomMMMU reveals that product images do not consistently improve performance and can, in some cases, degrade it. This indicates that MLLMs may struggle to effectively leverage rich visual content for e-commerce tasks. Building on these insights, we propose SUMEI, a data-driven method that strategically utilizes multiple images via predicting visual utilities before using them for downstream tasks. Comprehensive experiments demonstrate the effectiveness and robustness of SUMEI. The data and code are available through https://anonymous.4open.science/r/submission25.△ Less",
    "submitted_date_raw": "Submitted 21 August, 2025; originally announced August 2025.",
    "identity_key": "2508.15721"
  },
  {
    "title": "Tutorial on the Probabilistic Unification of Estimation Theory, Machine Learning, and Generative AI",
    "abs_url": "https://arxiv.org/abs/2508.15719",
    "pdf_url": "https://arxiv.org/pdf/2508.15719",
    "authors": [
      "Mohammed Elmusrati"
    ],
    "abstract": "Extracting meaning from uncertain, noisy data is a fundamental problem across time series analysis, pattern recognition, and language modeling. This survey presents a unified mathematical framework that connects classical estimation theory, statistical inference, and modern machine learning, including deep learning and large language models. By analyzing how techniques such as maximum likelihood estimation, Bayesian inference, and attention mechanisms address uncertainty, the paper illustrates that many AI methods are rooted in shared probabilistic principles. Through illustrative scenarios including system identification, image classification, and language generation, we show how increasingly complex models build upon these foundations to tackle practical challenges like overfitting, data sparsity, and interpretability. In other words, the work demonstrates that maximum likelihood, MAP estimation, Bayesian classification, and deep learning all represent different facets of a shared goal: inferring hidden causes from noisy and/or biased observations. It serves as both a theoretical synthesis and a practical guide for students and researchers navigating the evolving landscape of machine learning.△ Less",
    "submitted_date_raw": "Submitted 21 August, 2025; originally announced August 2025.",
    "identity_key": "2508.15719"
  },
  {
    "title": "StreamMem: Query-Agnostic KV Cache Memory for Streaming Video Understanding",
    "abs_url": "https://arxiv.org/abs/2508.15717",
    "pdf_url": "https://arxiv.org/pdf/2508.15717",
    "authors": [
      "Yanlai Yang",
      "Zhuokai Zhao",
      "Satya Narayan Shukla",
      "Aashu Singh",
      "Shlok Kumar Mishra",
      "Lizhu Zhang",
      "Mengye Ren"
    ],
    "abstract": "Multimodal large language models (MLLMs) have made significant progress in visual-language reasoning, but their ability to efficiently handle long videos remains limited. Despite recent advances in long-context MLLMs, storing and attending to the key-value (KV) cache for long visual contexts incurs substantial memory and computational overhead. Existing visual compression methods require either encoding the entire visual context before compression or having access to the questions in advance, which is impractical for long video understanding and multi-turn conversational settings. In this work, we propose StreamMem, a query-agnostic KV cache memory mechanism for streaming video understanding. Specifically, StreamMem encodes new video frames in a streaming manner, compressing the KV cache using attention scores between visual tokens and generic query tokens, while maintaining a fixed-size KV memory to enable efficient question answering (QA) in memory-constrained, long-video scenarios. Evaluation on three long video understanding and two streaming video question answering benchmarks shows that StreamMem achieves state-of-the-art performance in query-agnostic KV cache compression and is competitive with query-aware compression approaches.△ Less",
    "submitted_date_raw": "Submitted 21 August, 2025; originally announced August 2025.",
    "identity_key": "2508.15717"
  },
  {
    "title": "Foundation Models for Cross-Domain EEG Analysis Application: A Survey",
    "abs_url": "https://arxiv.org/abs/2508.15716",
    "pdf_url": "https://arxiv.org/pdf/2508.15716",
    "authors": [
      "Hongqi Li",
      "Yitong Chen",
      "Yujuan Wang",
      "Weihang Ni",
      "Haodong Zhang"
    ],
    "abstract": "Electroencephalography (EEG) analysis stands at the forefront of neuroscience and artificial intelligence research, where foundation models are reshaping the traditional EEG analysis paradigm by leveraging their powerful representational capacity and cross-modal generalization. However, the rapid proliferation of these techniques has led to a fragmented research landscape, characterized by diverse model roles, inconsistent architectures, and a lack of systematic categorization. To bridge this gap, this study presents the first comprehensive modality-oriented taxonomy for foundation models in EEG analysis, systematically organizing research advances based on output modalities of the native EEG decoding, EEG-text, EEG-vision, EEG-audio, and broader multimodal frameworks. We rigorously analyze each category's research ideas, theoretical foundations, and architectural innovations, while highlighting open challenges such as model interpretability, cross-domain generalization, and real-world applicability in EEG-based systems. By unifying this dispersed field, our work not only provides a reference framework for future methodology development but accelerates the translation of EEG foundation models into scalable, interpretable, and online actionable solutions.△ Less",
    "submitted_date_raw": "Submitted 21 August, 2025; originally announced August 2025.",
    "identity_key": "2508.15716"
  },
  {
    "title": "NiceWebRL: a Python library for human subject experiments with reinforcement learning environments",
    "abs_url": "https://arxiv.org/abs/2508.15693",
    "pdf_url": "https://arxiv.org/pdf/2508.15693",
    "authors": [
      "Wilka Carvalho",
      "Vikram Goddla",
      "Ishaan Sinha",
      "Hoon Shin",
      "Kunal Jha"
    ],
    "abstract": "We present NiceWebRL, a research tool that enables researchers to use machine reinforcement learning (RL) environments for online human subject experiments. NiceWebRL is a Python library that allows any Jax-based environment to be transformed into an online interface, supporting both single-agent and multi-agent environments. As such, NiceWebRL enables AI researchers to compare their algorithms to human performance, cognitive scientists to test ML algorithms as theories for human cognition, and multi-agent researchers to develop algorithms for human-AI collaboration. We showcase NiceWebRL with 3 case studies that demonstrate its potential to help develop Human-like AI, Human-compatible AI, and Human-assistive AI. In the first case study (Human-like AI), NiceWebRL enables the development of a novel RL model of cognition. Here, NiceWebRL facilitates testing this model against human participants in both a grid world and Craftax, a 2D Minecraft domain. In our second case study (Human-compatible AI), NiceWebRL enables the development of a novel multi-agent RL algorithm that can generalize to human partners in the Overcooked domain. Finally, in our third case study (Human-assistive AI), we show how NiceWebRL can allow researchers to study how an LLM can assist humans on complex tasks in XLand-Minigrid, an environment with millions of hierarchical tasks. The library is available at https://github.com/KempnerInstitute/nicewebrl.△ Less",
    "submitted_date_raw": "Submitted 21 August, 2025; originally announced August 2025.",
    "identity_key": "2508.15693"
  },
  {
    "title": "GRAFT: GRaPH and Table Reasoning for Textual Alignment -- A Benchmark for Structured Instruction Following and Visual Reasoning",
    "abs_url": "https://arxiv.org/abs/2508.15690",
    "pdf_url": "https://arxiv.org/pdf/2508.15690",
    "authors": [
      "Abhigya Verma",
      "Sriram Puttagunta",
      "Seganrasan Subramanian",
      "Sravan Ramachandran"
    ],
    "abstract": "GRAFT is a structured multimodal benchmark for evaluating models on instruction-following, visual reasoning, and visual-textual alignment tasks. It features programmatically generated charts and synthetically rendered tables, created with Python visualization libraries to ensure control over data semantics, structure, and clarity. Each GRAFT instance pairs a chart or table image with a systematically generated, multi-step analytical question based solely on visual content. Answers are provided in structured formats such as JSON or YAML, supporting consistent evaluation of both reasoning and output format. The benchmark introduces a taxonomy of reasoning types including comparison, trend identification, ranking, aggregation, proportion estimation, and anomaly detection to enable comprehensive assessment. Reference answers follow strict factual and formatting guidelines for precise, aspect-based evaluation. GRAFT offers a unified, scalable framework for fine-grained benchmarking of multimodal models on visually grounded, structured reasoning tasks, setting a new evaluation standard in this field.△ Less",
    "submitted_date_raw": "Submitted 21 August, 2025; originally announced August 2025.",
    "identity_key": "2508.15690"
  },
  {
    "title": "Row-Column Hybrid Grouping for Fault-Resilient Multi-Bit Weight Representation on IMC Arrays",
    "abs_url": "https://arxiv.org/abs/2508.15685",
    "pdf_url": "https://arxiv.org/pdf/2508.15685",
    "authors": [
      "Kang Eun Jeon",
      "Sangheum Yeon",
      "Jinhee Kim",
      "Hyeonsu Bang",
      "Johnny Rhe",
      "Jong Hwan Ko"
    ],
    "abstract": "This paper addresses two critical challenges in analog In-Memory Computing (IMC) systems that limit their scalability and deployability: the computational unreliability caused by stuck-at faults (SAFs) and the high compilation overhead of existing fault-mitigation algorithms, namely Fault-Free (FF). To overcome these limitations, we first propose a novel multi-bit weight representation technique, termed row-column hybrid grouping, which generalizes conventional column grouping by introducing redundancy across both rows and columns. This structural redundancy enhances fault tolerance and can be effectively combined with existing fault-mitigation solutions. Second, we design a compiler pipeline that reformulates the fault-aware weight decomposition problem as an Integer Linear Programming (ILP) task, enabling fast and scalable compilation through off-the-shelf solvers. Further acceleration is achieved through theoretical insights that identify fault patterns amenable to trivial solutions, significantly reducing computation. Experimental results on convolutional networks and small language models demonstrate the effectiveness of our approach, achieving up to 8%p improvement in accuracy, 150x faster compilation, and 2x energy efficiency gain compared to existing baselines.△ Less",
    "submitted_date_raw": "Submitted 21 August, 2025; originally announced August 2025.",
    "identity_key": "2508.15685"
  },
  {
    "title": "Futurity as Infrastructure: A Techno-Philosophical Interpretation of the AI Lifecycle",
    "abs_url": "https://arxiv.org/abs/2508.15680",
    "pdf_url": "https://arxiv.org/pdf/2508.15680",
    "authors": [
      "Mark Cote",
      "Susana Aires"
    ],
    "abstract": "This paper argues that a techno-philosophical reading of the EU AI Act provides insight into the long-term dynamics of data in AI systems, specifically, how the lifecycle from ingestion to deployment generates recursive value chains that challenge existing frameworks for Responsible AI. We introduce a conceptual tool to frame the AI pipeline, spanning data, training regimes, architectures, feature stores, and transfer learning. Using cross-disciplinary methods, we develop a technically grounded and philosophically coherent analysis of regulatory blind spots. Our central claim is that what remains absent from policymaking is an account of the dynamic of becoming that underpins both the technical operation and economic logic of AI. To address this, we advance a formal reading of AI inspired by Simondonian philosophy of technology, reworking his concept of individuation to model the AI lifecycle, including the pre-individual milieu, individuation, and individuated AI. To translate these ideas, we introduce futurity: the self-reinforcing lifecycle of AI, where more data enhances performance, deepens personalisation, and expands application domains. Futurity highlights the recursively generative, non-rivalrous nature of data, underpinned by infrastructures like feature stores that enable feedback, adaptation, and temporal recursion. Our intervention foregrounds escalating power asymmetries, particularly the tech oligarchy whose infrastructures of capture, training, and deployment concentrate value and decision-making. We argue that effective regulation must address these infrastructural and temporal dynamics, and propose measures including lifecycle audits, temporal traceability, feedback accountability, recursion transparency, and a right to contest recursive reuse.△ Less",
    "submitted_date_raw": "Submitted 21 August, 2025; originally announced August 2025.",
    "identity_key": "2508.15680"
  },
  {
    "title": "Mind and Motion Aligned: A Joint Evaluation IsaacSim Benchmark for Task Planning and Low-Level Policies in Mobile Manipulation",
    "abs_url": "https://arxiv.org/abs/2508.15663",
    "pdf_url": "https://arxiv.org/pdf/2508.15663",
    "authors": [
      "Nikita Kachaev",
      "Andrei Spiridonov",
      "Andrey Gorodetsky",
      "Kirill Muravyev",
      "Nikita Oskolkov",
      "Aditya Narendra",
      "Vlad Shakhuro",
      "Dmitry Makarov",
      "Aleksandr I. Panov",
      "Polina Fedotova",
      "Alexey K. Kovalev"
    ],
    "abstract": "Benchmarks are crucial for evaluating progress in robotics and embodied AI. However, a significant gap exists between benchmarks designed for high-level language instruction following, which often assume perfect low-level execution, and those for low-level robot control, which rely on simple, one-step commands. This disconnect prevents a comprehensive evaluation of integrated systems where both task planning and physical execution are critical. To address this, we propose Kitchen-R, a novel benchmark that unifies the evaluation of task planning and low-level control within a simulated kitchen environment. Built as a digital twin using the Isaac Sim simulator and featuring more than 500 complex language instructions, Kitchen-R supports a mobile manipulator robot. We provide baseline methods for our benchmark, including a task-planning strategy based on a vision-language model and a low-level control policy based on diffusion policy. We also provide a trajectory collection system. Our benchmark offers a flexible framework for three evaluation modes: independent assessment of the planning module, independent assessment of the control policy, and, crucially, an integrated evaluation of the whole system. Kitchen-R bridges a key gap in embodied AI research, enabling more holistic and realistic benchmarking of language-guided robotic agents.△ Less",
    "submitted_date_raw": "Submitted 21 August, 2025; originally announced August 2025.",
    "identity_key": "2508.15663"
  },
  {
    "title": "Benchmarking Computer Science Survey Generation",
    "abs_url": "https://arxiv.org/abs/2508.15658",
    "pdf_url": "https://arxiv.org/pdf/2508.15658",
    "authors": [
      "Weihang Su",
      "Anzhe Xie",
      "Qingyao Ai",
      "Jianming Long",
      "Jiaxin Mao",
      "Ziyi Ye",
      "Yiqun Liu"
    ],
    "abstract": "Scientific survey articles play a vital role in summarizing research progress, yet their manual creation is becoming increasingly infeasible due to the rapid growth of academic literature. While large language models (LLMs) offer promising capabilities for automating this process, progress in this area is hindered by the absence of standardized benchmarks and evaluation protocols. To address this gap, we introduce SurGE (Survey Generation Evaluation), a new benchmark for evaluating scientific survey generation in the computer science domain. SurGE consists of (1) a collection of test instances, each including a topic description, an expert-written survey, and its full set of cited references, and (2) a large-scale academic corpus of over one million papers that serves as the retrieval pool. In addition, we propose an automated evaluation framework that measures generated surveys across four dimensions: information coverage, referencing accuracy, structural organization, and content quality. Our evaluation of diverse LLM-based approaches shows that survey generation remains highly challenging, even for advanced self-reflection frameworks. These findings highlight the complexity of the task and the necessity for continued research. We have open-sourced all the code, data, and models at: https://github.com/oneal2000/SurGE△ Less",
    "submitted_date_raw": "Submitted 21 August, 2025; originally announced August 2025.",
    "identity_key": "2508.15658"
  },
  {
    "title": "Understanding Action Effects through Instrumental Empowerment in Multi-Agent Reinforcement Learning",
    "abs_url": "https://arxiv.org/abs/2508.15652",
    "pdf_url": "https://arxiv.org/pdf/2508.15652",
    "authors": [
      "Ardian Selmonaj",
      "Miroslav Strupl",
      "Oleg Szehr",
      "Alessandro Antonucci"
    ],
    "abstract": "To reliably deploy Multi-Agent Reinforcement Learning (MARL) systems, it is crucial to understand individual agent behaviors within a team. While prior work typically evaluates overall team performance based on explicit reward signals or learned value functions, it is unclear how to infer agent contributions in the absence of any value feedback. In this work, we investigate whether meaningful insights into agent behaviors can be extracted that are consistent with the underlying value functions, solely by analyzing the policy distribution. Inspired by the phenomenon that intelligent agents tend to pursue convergent instrumental values, which generally increase the likelihood of task success, we introduce Intended Cooperation Values (ICVs), a method based on information-theoretic Shapley values for quantifying each agent's causal influence on their co-players' instrumental empowerment. Specifically, ICVs measure an agent's action effect on its teammates' policies by assessing their decision uncertainty and preference alignment. The analysis across cooperative and competitive MARL environments reveals the extent to which agents adopt similar or diverse strategies. By comparing action effects between policies and value functions, our method identifies which agent behaviors are beneficial to team success, either by fostering deterministic decisions or by preserving flexibility for future action choices. Our proposed method offers novel insights into cooperation dynamics and enhances explainability in MARL systems.△ Less",
    "submitted_date_raw": "Submitted 21 August, 2025; originally announced August 2025.",
    "identity_key": "2508.15652"
  },
  {
    "title": "Towards a 3D Transfer-based Black-box Attack via Critical Feature Guidance",
    "abs_url": "https://arxiv.org/abs/2508.15650",
    "pdf_url": "https://arxiv.org/pdf/2508.15650",
    "authors": [
      "Shuchao Pang",
      "Zhenghan Chen",
      "Shen Zhang",
      "Liming Lu",
      "Siyuan Liang",
      "Anan Du",
      "Yongbin Zhou"
    ],
    "abstract": "Deep neural networks for 3D point clouds have been demonstrated to be vulnerable to adversarial examples. Previous 3D adversarial attack methods often exploit certain information about the target models, such as model parameters or outputs, to generate adversarial point clouds. However, in realistic scenarios, it is challenging to obtain any information about the target models under conditions of absolute security. Therefore, we focus on transfer-based attacks, where generating adversarial point clouds does not require any information about the target models. Based on our observation that the critical features used for point cloud classification are consistent across different DNN architectures, we propose CFG, a novel transfer-based black-box attack method that improves the transferability of adversarial point clouds via the proposed Critical Feature Guidance. Specifically, our method regularizes the search of adversarial point clouds by computing the importance of the extracted features, prioritizing the corruption of critical features that are likely to be adopted by diverse architectures. Further, we explicitly constrain the maximum deviation extent of the generated adversarial point clouds in the loss function to ensure their imperceptibility. Extensive experiments conducted on the ModelNet40 and ScanObjectNN benchmark datasets demonstrate that the proposed CFG outperforms the state-of-the-art attack methods by a large margin.△ Less",
    "submitted_date_raw": "Submitted 21 August, 2025; originally announced August 2025.",
    "identity_key": "2508.15650"
  },
  {
    "title": "Label Uncertainty for Ultrasound Segmentation",
    "abs_url": "https://arxiv.org/abs/2508.15635",
    "pdf_url": "https://arxiv.org/pdf/2508.15635",
    "authors": [
      "Malini Shivaram",
      "Gautam Rajendrakumar Gare",
      "Laura Hutchins",
      "Jacob Duplantis",
      "Thomas Deiss",
      "Thales Nogueira Gomes",
      "Thong Tran",
      "Keyur H. Patel",
      "Thomas H Fox",
      "Amita Krishnan",
      "Deva Ramanan",
      "Bennett DeBoisblanc",
      "Ricardo Rodriguez",
      "John Galeotti"
    ],
    "abstract": "In medical imaging, inter-observer variability among radiologists often introduces label uncertainty, particularly in modalities where visual interpretation is subjective. Lung ultrasound (LUS) is a prime example-it frequently presents a mixture of highly ambiguous regions and clearly discernible structures, making consistent annotation challenging even for experienced clinicians. In this work, we introduce a novel approach to both labeling and training AI models using expert-supplied, per-pixel confidence values. Rather than treating annotations as absolute ground truth, we design a data annotation protocol that captures the confidence that radiologists have in each labeled region, modeling the inherent aleatoric uncertainty present in real-world clinical data. We demonstrate that incorporating these confidence values during training leads to improved segmentation performance. More importantly, we show that this enhanced segmentation quality translates into better performance on downstream clinically-critical tasks-specifically, estimating S/F oxygenation ratio values, classifying S/F ratio change, and predicting 30-day patient readmission. While we empirically evaluate many methods for exposing the uncertainty to the learning model, we find that a simple approach that trains a model on binarized labels obtained with a (60%) confidence threshold works well. Importantly, high thresholds work far better than a naive approach of a 50% threshold, indicating that training on very confident pixels is far more effective. Our study systematically investigates the impact of training with varying confidence thresholds, comparing not only segmentation metrics but also downstream clinical outcomes. These results suggest that label confidence is a valuable signal that, when properly leveraged, can significantly enhance the reliability and clinical utility of AI in medical imaging.△ Less",
    "submitted_date_raw": "Submitted 21 August, 2025; originally announced August 2025.",
    "identity_key": "2508.15635"
  },
  {
    "title": "GRASPED: Graph Anomaly Detection using Autoencoder with Spectral Encoder and Decoder (Full Version)",
    "abs_url": "https://arxiv.org/abs/2508.15633",
    "pdf_url": "https://arxiv.org/pdf/2508.15633",
    "authors": [
      "Wei Herng Choong",
      "Jixing Liu",
      "Ching-Yu Kao",
      "Philip Sperl"
    ],
    "abstract": "Graph machine learning has been widely explored in various domains, such as community detection, transaction analysis, and recommendation systems. In these applications, anomaly detection plays an important role. Recently, studies have shown that anomalies on graphs induce spectral shifts. Some supervised methods have improved the utilization of such spectral domain information. However, they remain limited by the scarcity of labeled data due to the nature of anomalies. On the other hand, existing unsupervised learning approaches predominantly rely on spatial information or only employ low-pass filters, thereby losing the capacity for multi-band analysis. In this paper, we propose Graph Autoencoder with Spectral Encoder and Spectral Decoder (GRASPED) for node anomaly detection. Our unsupervised learning model features an encoder based on Graph Wavelet Convolution, along with structural and attribute decoders. The Graph Wavelet Convolution-based encoder, combined with a Wiener Graph Deconvolution-based decoder, exhibits bandpass filter characteristics that capture global and local graph information at multiple scales. This design allows for a learning-based reconstruction of node attributes, effectively capturing anomaly information. Extensive experiments on several real-world graph anomaly detection datasets demonstrate that GRASPED outperforms current state-of-the-art models.△ Less",
    "submitted_date_raw": "Submitted 21 August, 2025; originally announced August 2025.",
    "identity_key": "2508.15633"
  },
  {
    "title": "Adapting A Vector-Symbolic Memory for Lisp ACT-R",
    "abs_url": "https://arxiv.org/abs/2508.15630",
    "pdf_url": "https://arxiv.org/pdf/2508.15630",
    "authors": [
      "Meera Ray",
      "Christopher L. Dancy"
    ],
    "abstract": "Holographic Declarative Memory (HDM) is a vector-symbolic alternative to ACT-R's Declarative Memory (DM) system that can bring advantages such as scalability and architecturally defined similarity between DM chunks. We adapted HDM to work with the most comprehensive and widely-used implementation of ACT-R (Lisp ACT-R) so extant ACT-R models designed with DM can be run with HDM without major changes. With this adaptation of HDM, we have developed vector-based versions of common ACT-R functions, set up a text processing pipeline to add the contents of large documents to ACT-R memory, and most significantly created a useful and novel mechanism to retrieve an entire chunk of memory based on a request using only vector representations of tokens. Preliminary results indicate that we can maintain vector-symbolic advantages of HDM (e.g., chunk recall without storing the actual chunk and other advantages with scaling) while also extending it so that previous ACT-R models may work with the system with little (or potentially no) modifications within the actual procedural and declarative memory portions of a model. As a part of iterative improvement of this newly translated holographic declarative memory module, we will continue to explore better time-context representations for vectors to improve the module's ability to reconstruct chunks during recall. To more fully test this translated HDM module, we also plan to develop decision-making models that use instance-based learning (IBL) theory, which is a useful application of HDM given the advantages of the system.△ Less",
    "submitted_date_raw": "Submitted 21 August, 2025; originally announced August 2025.",
    "identity_key": "2508.15630"
  },
  {
    "title": "Trained Miniatures: Low cost, High Efficacy SLMs for Sales & Marketing",
    "abs_url": "https://arxiv.org/abs/2508.15617",
    "pdf_url": "https://arxiv.org/pdf/2508.15617",
    "authors": [
      "Ishaan Bhola",
      "Mukunda NS",
      "Sravanth Kurmala",
      "Harsh Nandwani",
      "Arihant Jain"
    ],
    "abstract": "Large language models (LLMs) excel in text generation; however, these creative elements require heavy computation and are accompanied by a steep cost. Especially for targeted applications such as sales and marketing outreach, these costs are far from feasible. This paper introduces the concept of \"Trained Miniatures\" - Small Language Models(SLMs) fine-tuned for specific, high-value applications, generating similar domain-specific responses for a fraction of the cost.△ Less",
    "submitted_date_raw": "Submitted 21 August, 2025; originally announced August 2025.",
    "identity_key": "2508.15617"
  },
  {
    "title": "Transduction is All You Need for Structured Data Workflows",
    "abs_url": "https://arxiv.org/abs/2508.15610",
    "pdf_url": "https://arxiv.org/pdf/2508.15610",
    "authors": [
      "Alfio Gliozzo",
      "Naweed Khan",
      "Christodoulos Constantinides",
      "Nandana Mihindukulasooriya",
      "Nahuel Defosse",
      "Junkyu Lee"
    ],
    "abstract": "This paper introduces Agentics, a modular framework for building agent-based systems capable of structured reasoning and compositional generalization over complex data. Designed with research and practical applications in mind, Agentics offers a novel perspective on working with data and AI workflows. In this framework, agents are abstracted from the logical flow and they are used internally to the data type to enable logical transduction among data. Agentics encourages AI developers to focus on modeling data rather than crafting prompts, enabling a declarative language in which data types are provided by LLMs and composed through logical transduction, which is executed by LLMs when types are connected. We provide empirical evidence demonstrating the applicability of this framework across domain-specific multiple-choice question answering, semantic parsing for text-to-SQL, and automated prompt optimization tasks, achieving state-of-the-art accuracy or improved scalability without sacrificing performance. The open-source implementation is available at \\texttt{https://github.com/IBM/agentics}.△ Less",
    "submitted_date_raw": "Submitted 21 August, 2025; originally announced August 2025.",
    "identity_key": "2508.15610"
  },
  {
    "title": "Are Virtual DES Images a Valid Alternative to the Real Ones?",
    "abs_url": "https://arxiv.org/abs/2508.15594",
    "pdf_url": "https://arxiv.org/pdf/2508.15594",
    "authors": [
      "Ana C. Perre",
      "Luís A. Alexandre",
      "Luís C. Freire"
    ],
    "abstract": "Contrast-enhanced spectral mammography (CESM) is an imaging modality that provides two types of images, commonly known as low-energy (LE) and dual-energy subtracted (DES) images. In many domains, particularly in medicine, the emergence of image-to-image translation techniques has enabled the artificial generation of images using other images as input. Within CESM, applying such techniques to generate DES images from LE images could be highly beneficial, potentially reducing patient exposure to radiation associated with high-energy image acquisition. In this study, we investigated three models for the artificial generation of DES images (virtual DES): a pre-trained U-Net model, a U-Net trained end-to-end model, and a CycleGAN model. We also performed a series of experiments to assess the impact of using virtual DES images on the classification of CESM examinations into malignant and non-malignant categories. To our knowledge, this is the first study to evaluate the impact of virtual DES images on CESM lesion classification. The results demonstrate that the best performance was achieved with the pre-trained U-Net model, yielding an F1 score of 85.59% when using the virtual DES images, compared to 90.35% with the real DES images. This discrepancy likely results from the additional diagnostic information in real DES images, which contributes to a higher classification accuracy. Nevertheless, the potential for virtual DES image generation is considerable and future advancements may narrow this performance gap to a level where exclusive reliance on virtual DES images becomes clinically viable.△ Less",
    "submitted_date_raw": "Submitted 21 August, 2025; originally announced August 2025.",
    "identity_key": "2508.15594"
  },
  {
    "title": "A Dynamical Systems Framework for Reinforcement Learning Safety and Robustness Verification",
    "abs_url": "https://arxiv.org/abs/2508.15588",
    "pdf_url": "https://arxiv.org/pdf/2508.15588",
    "authors": [
      "Ahmed Nasir",
      "Abdelhafid Zenati"
    ],
    "abstract": "The application of reinforcement learning to safety-critical systems is limited by the lack of formal methods for verifying the robustness and safety of learned policies. This paper introduces a novel framework that addresses this gap by analyzing the combination of an RL agent and its environment as a discrete-time autonomous dynamical system. By leveraging tools from dynamical systems theory, specifically the Finite-Time Lyapunov Exponent (FTLE), we identify and visualize Lagrangian Coherent Structures (LCS) that act as the hidden \"skeleton\" governing the system's behavior. We demonstrate that repelling LCS function as safety barriers around unsafe regions, while attracting LCS reveal the system's convergence properties and potential failure modes, such as unintended \"trap\" states. To move beyond qualitative visualization, we introduce a suite of quantitative metrics, Mean Boundary Repulsion (MBR), Aggregated Spurious Attractor Strength (ASAS), and Temporally-Aware Spurious Attractor Strength (TASAS), to formally measure a policy's safety margin and robustness. We further provide a method for deriving local stability guarantees and extend the analysis to handle model uncertainty. Through experiments in both discrete and continuous control environments, we show that this framework provides a comprehensive and interpretable assessment of policy behavior, successfully identifying critical flaws in policies that appear successful based on reward alone.△ Less",
    "submitted_date_raw": "Submitted 21 August, 2025; originally announced August 2025.",
    "identity_key": "2508.15588"
  },
  {
    "title": "LoUQAL: Low-fidelity informed Uncertainty Quantification for Active Learning in the chemical configuration space",
    "abs_url": "https://arxiv.org/abs/2508.15577",
    "pdf_url": "https://arxiv.org/pdf/2508.15577",
    "authors": [
      "Vivin Vinod",
      "Peter Zaspel"
    ],
    "abstract": "Uncertainty quantification is an important scheme in active learning techniques, including applications in predicting quantum chemical properties. In quantum chemical calculations, there exists the notion of a fidelity, a less accurate computation is accessible at a cheaper computational cost. This work proposes a novel low-fidelity informed uncertainty quantification for active learning with applications in predicting diverse quantum chemical properties such as excitation energies and \\textit{ab initio} potential energy surfaces. Computational experiments are carried out in order to assess the proposed method with results demonstrating that models trained with the novel method outperform alternatives in terms of empirical error and number of iterations required. The effect of the choice of fidelity is also studied to perform a thorough benchmark.△ Less",
    "submitted_date_raw": "Submitted 21 August, 2025; originally announced August 2025.",
    "identity_key": "2508.15577"
  },
  {
    "title": "DeepThink3D: Enhancing Large Language Models with Programmatic Reasoning in Complex 3D Situated Reasoning Tasks",
    "abs_url": "https://arxiv.org/abs/2508.15548",
    "pdf_url": "https://arxiv.org/pdf/2508.15548",
    "authors": [
      "Jiayi Song",
      "Rui Wan",
      "Lipeng Ma",
      "Weidong Yang",
      "Qingyuan Zhou",
      "Yixuan Li",
      "Ben Fei"
    ],
    "abstract": "This work enhances the ability of large language models (LLMs) to perform complex reasoning in 3D scenes. Recent work has addressed the 3D situated reasoning task by invoking tool usage through large language models. Large language models call tools via APIs and integrate the generated programs through a chain of thought to solve problems based on the program results. However, due to the simplicity of the questions in the dataset, the generated program reasoning chains are relatively short. To solve this main challenge, in this paper, we introduce DeepThink3D to enhance the tool usage of LLMs in complex 3D situated reasoning tasks. Our work proposes a combinatorial and iterative evolutionary approach on the SQA3D benchmark to generate more complex questions. Building on this foundation, we fine-tune the large language model to make it more proficient in using 3D tools. By employing Direct Preference Optimization (DPO), we directly optimize the toolchain strategies generated by models, thereby enhancing their accuracy in complex tasks.△ Less",
    "submitted_date_raw": "Submitted 21 August, 2025; originally announced August 2025.",
    "identity_key": "2508.15548"
  },
  {
    "title": "Super-additive Cooperation in Language Model Agents",
    "abs_url": "https://arxiv.org/abs/2508.15510",
    "pdf_url": "https://arxiv.org/pdf/2508.15510",
    "authors": [
      "Filippo Tonini",
      "Lukas Galke"
    ],
    "abstract": "With the prospect of autonomous artificial intelligence (AI) agents, studying their tendency for cooperative behavior becomes an increasingly relevant topic. This study is inspired by the super-additive cooperation theory, where the combined effects of repeated interactions and inter-group rivalry have been argued to be the cause for cooperative tendencies found in humans. We devised a virtual tournament where language model agents, grouped into teams, face each other in a Prisoner's Dilemma game. By simulating both internal team dynamics and external competition, we discovered that this blend substantially boosts both overall and initial, one-shot cooperation levels (the tendency to cooperate in one-off interactions). This research provides a novel framework for large language models to strategize and act in complex social scenarios and offers evidence for how intergroup competition can, counter-intuitively, result in more cooperative behavior. These insights are crucial for designing future multi-agent AI systems that can effectively work together and better align with human values. Source code is available at https://github.com/pippot/Superadditive-cooperation-LLMs.△ Less",
    "submitted_date_raw": "Submitted 21 August, 2025; originally announced August 2025.",
    "identity_key": "2508.15510"
  },
  {
    "title": "Think in Blocks: Adaptive Reasoning from Direct Response to Deep Reasoning",
    "abs_url": "https://arxiv.org/abs/2508.15507",
    "pdf_url": "https://arxiv.org/pdf/2508.15507",
    "authors": [
      "Yekun Zhu",
      "Guang Chen",
      "Chengjun Mao"
    ],
    "abstract": "Large Language Models (LLMs) with chains-of-thought have demonstrated strong performance on an increasing range of tasks, particularly those involving complex logical reasoning. However, excessively long chains can lead to overthinking, causing computational waste and slower responses. This raises a question: can LLMs dynamically adjust the length of their reasoning processes based on task complexity? To address this, we propose the Think in Blocks framework, which enables adaptive reasoning-from zero to deep reasoning-by partitioning the reasoning process into a tunable number of blocks. Our main contributions are: (1) Establishing an explicit block-structured paradigm in which the model first predicts an integer reasoning budget-the number of blocks-and then partitions its reasoning accordingly; (2) Training an adaptive model through a three-stage pipeline-Supervised Fine-Tuning, reward-guided Direct Preference Optimization, and Reinforcement Learning-that adjusts its reasoning depth to problem difficulty; (3) Exploiting the explicit block count to dynamically control reasoning depth at inference time, allowing flexible adjustment of chain-of-thought length during deployment.△ Less",
    "submitted_date_raw": "Submitted 21 August, 2025; originally announced August 2025.",
    "identity_key": "2508.15507"
  },
  {
    "title": "LLM-Driven Self-Refinement for Embodied Drone Task Planning",
    "abs_url": "https://arxiv.org/abs/2508.15501",
    "pdf_url": "https://arxiv.org/pdf/2508.15501",
    "authors": [
      "Deyu Zhang",
      "Xicheng Zhang",
      "Jiahao Li",
      "Tingting Long",
      "Xunhua Dai",
      "Yongjian Fu",
      "Jinrui Zhang",
      "Ju Ren",
      "Yaoxue Zhang"
    ],
    "abstract": "We introduce SRDrone, a novel system designed for self-refinement task planning in industrial-grade embodied drones. SRDrone incorporates two key technical contributions: First, it employs a continuous state evaluation methodology to robustly and accurately determine task outcomes and provide explanatory feedback. This approach supersedes conventional reliance on single-frame final-state assessment for continuous, dynamic drone operations. Second, SRDrone implements a hierarchical Behavior Tree (BT) modification model. This model integrates multi-level BT plan analysis with a constrained strategy space to enable structured reflective learning from experience. Experimental results demonstrate that SRDrone achieves a 44.87% improvement in Success Rate (SR) over baseline methods. Furthermore, real-world deployment utilizing an experience base optimized through iterative self-refinement attains a 96.25% SR. By embedding adaptive task refinement capabilities within an industrial-grade BT planning framework, SRDrone effectively integrates the general reasoning intelligence of Large Language Models (LLMs) with the stringent physical execution constraints inherent to embodied drones. Code is available at https://github.com/ZXiiiC/SRDrone.△ Less",
    "submitted_date_raw": "Submitted 21 August, 2025; originally announced August 2025.",
    "identity_key": "2508.15501"
  },
  {
    "title": "LGMSNet: Thinning a medical image segmentation model via dual-level multiscale fusion",
    "abs_url": "https://arxiv.org/abs/2508.15476",
    "pdf_url": "https://arxiv.org/pdf/2508.15476",
    "authors": [
      "Chengqi Dong",
      "Fenghe Tang",
      "Rongge Mao",
      "Xinpei Gao",
      "S. Kevin Zhou"
    ],
    "abstract": "Medical image segmentation plays a pivotal role in disease diagnosis and treatment planning, particularly in resource-constrained clinical settings where lightweight and generalizable models are urgently needed. However, existing lightweight models often compromise performance for efficiency and rarely adopt computationally expensive attention mechanisms, severely restricting their global contextual perception capabilities. Additionally, current architectures neglect the channel redundancy issue under the same convolutional kernels in medical imaging, which hinders effective feature extraction. To address these challenges, we propose LGMSNet, a novel lightweight framework based on local and global dual multiscale that achieves state-of-the-art performance with minimal computational overhead. LGMSNet employs heterogeneous intra-layer kernels to extract local high-frequency information while mitigating channel redundancy. In addition, the model integrates sparse transformer-convolutional hybrid branches to capture low-frequency global information. Extensive experiments across six public datasets demonstrate LGMSNet's superiority over existing state-of-the-art methods. In particular, LGMSNet maintains exceptional performance in zero-shot generalization tests on four unseen datasets, underscoring its potential for real-world deployment in resource-limited medical scenarios. The whole project code is in https://github.com/cq-dong/LGMSNet.△ Less",
    "submitted_date_raw": "Submitted 21 August, 2025; originally announced August 2025.",
    "identity_key": "2508.15476"
  },
  {
    "title": "Subjective Behaviors and Preferences in LLM: Language of Browsing",
    "abs_url": "https://arxiv.org/abs/2508.15474",
    "pdf_url": "https://arxiv.org/pdf/2508.15474",
    "authors": [
      "Sai Sundaresan",
      "Harshita Chopra",
      "Atanu R. Sinha",
      "Koustava Goswami",
      "Nagasai Saketh Naidu",
      "Raghav Karan",
      "N Anushka"
    ],
    "abstract": "A Large Language Model (LLM) offers versatility across domains and tasks, purportedly benefiting users with a wide variety of behaviors and preferences. We question this perception about an LLM when users have inherently subjective behaviors and preferences, as seen in their ubiquitous and idiosyncratic browsing of websites or apps. The sequential behavior logs of pages, thus generated, form something akin to each user's self-constructed \"language\", albeit without the structure and grammar imbued in natural languages. We ask: (i) Can a small LM represent the \"language of browsing\" better than a large LM? (ii) Can an LM with a single set of parameters (or, single LM) adequately capture myriad users' heterogeneous, subjective behaviors and preferences? (iii) Can a single LM with high average performance, yield low variance in performance to make alignment good at user level? We introduce clusterwise LM training, HeTLM (Heterogeneity aware Training of Language Model), appropriate for subjective behaviors. We find that (i) a small LM trained using a page-level tokenizer outperforms large pretrained or finetuned LMs; (ii) HeTLM with heterogeneous cluster specific set of parameters outperforms a single LM of the same family, controlling for the number of parameters; and (iii) a higher mean and a lower variance in generation ensues, implying improved alignment.△ Less",
    "submitted_date_raw": "Submitted 21 August, 2025; originally announced August 2025.",
    "identity_key": "2508.15474"
  },
  {
    "title": "RadReason: Radiology Report Evaluation Metric with Reasons and Sub-Scores",
    "abs_url": "https://arxiv.org/abs/2508.15464",
    "pdf_url": "https://arxiv.org/pdf/2508.15464",
    "authors": [
      "Yingshu Li",
      "Yunyi Liu",
      "Lingqiao Liu",
      "Lei Wang",
      "Luping Zhou"
    ],
    "abstract": "Evaluating automatically generated radiology reports remains a fundamental challenge due to the lack of clinically grounded, interpretable, and fine-grained metrics. Existing methods either produce coarse overall scores or rely on opaque black-box models, limiting their usefulness in real-world clinical workflows. We introduce RadReason, a novel evaluation framework for radiology reports that not only outputs fine-grained sub-scores across six clinically defined error types, but also produces human-readable justifications that explain the rationale behind each score. Our method builds on Group Relative Policy Optimization and incorporates two key innovations: (1) Sub-score Dynamic Weighting, which adaptively prioritizes clinically challenging error types based on live F1 statistics; and (2) Majority-Guided Advantage Scaling, which adjusts policy gradient updates based on prompt difficulty derived from sub-score agreement. Together, these components enable more stable optimization and better alignment with expert clinical judgment. Experiments on the ReXVal benchmark show that RadReason surpasses all prior offline metrics and achieves parity with GPT-4-based evaluations, while remaining explainable, cost-efficient, and suitable for clinical deployment. Code will be released upon publication.△ Less",
    "submitted_date_raw": "Submitted 21 August, 2025; originally announced August 2025.",
    "identity_key": "2508.15464"
  },
  {
    "title": "A Solvable Molecular Switch Model for Stable Temporal Information Processing",
    "abs_url": "https://arxiv.org/abs/2508.15451",
    "pdf_url": "https://arxiv.org/pdf/2508.15451",
    "authors": [
      "H. I. Nurdin",
      "C. A. Nijhuis"
    ],
    "abstract": "This paper studies an input-driven one-state differential equation model initially developed for an experimentally demonstrated dynamic molecular switch that switches like synapses in the brain do. The linear-in-the-state and nonlinear-in-the-input model is exactly solvable, and it is shown that it also possesses mathematical properties of convergence and fading memory that enable stable processing of time-varying inputs by nonlinear dynamical systems. Thus, the model exhibits the co-existence of biologically-inspired behavior and desirable mathematical properties for stable learning on sequential data. The results give theoretical support for the use of the dynamic molecular switches as computational units in deep cascaded/layered feedforward and recurrent architectures as well as other more general structures for neuromorphic computing. They could also inspire more general exactly solvable models that can be fitted to emulate arbitrary physical devices which can mimic brain-inspired behaviour and perform stable computation on input signals.△ Less",
    "submitted_date_raw": "Submitted 21 August, 2025; originally announced August 2025.",
    "identity_key": "2508.15451"
  },
  {
    "title": "Reliable Unlearning Harmful Information in LLMs with Metamorphosis Representation Projection",
    "abs_url": "https://arxiv.org/abs/2508.15449",
    "pdf_url": "https://arxiv.org/pdf/2508.15449",
    "authors": [
      "Chengcan Wu",
      "Zeming Wei",
      "Huanran Chen",
      "Yinpeng Dong",
      "Meng Sun"
    ],
    "abstract": "While Large Language Models (LLMs) have demonstrated impressive performance in various domains and tasks, concerns about their safety are becoming increasingly severe. In particular, since models may store unsafe knowledge internally, machine unlearning has emerged as a representative paradigm to ensure model safety. Existing approaches employ various training techniques, such as gradient ascent and negative preference optimization, in attempts to eliminate the influence of undesired data on target models. However, these methods merely suppress the activation of undesired data through parametric training without completely eradicating its informational traces within the model. This fundamental limitation makes it difficult to achieve effective continuous unlearning, rendering these methods vulnerable to relearning attacks. To overcome these challenges, we propose a Metamorphosis Representation Projection (MRP) approach that pioneers the application of irreversible projection properties to machine unlearning. By implementing projective transformations in the hidden state space of specific network layers, our method effectively eliminates harmful information while preserving useful knowledge. Experimental results demonstrate that our approach enables effective continuous unlearning and successfully defends against relearning attacks, achieving state-of-the-art performance in unlearning effectiveness while preserving natural performance. Our code is available in https://github.com/ChengcanWu/MRP.△ Less",
    "submitted_date_raw": "Submitted 21 August, 2025; originally announced August 2025.",
    "identity_key": "2508.15449"
  },
  {
    "title": "From Bits to Boardrooms: A Cutting-Edge Multi-Agent LLM Framework for Business Excellence",
    "abs_url": "https://arxiv.org/abs/2508.15447",
    "pdf_url": "https://arxiv.org/pdf/2508.15447",
    "authors": [
      "Zihao Wang",
      "Junming Zhang"
    ],
    "abstract": "Large Language Models (LLMs) have shown promising potential in business applications, particularly in enterprise decision support and strategic planning, yet current approaches often struggle to reconcile intricate operational analyses with overarching strategic goals across diverse market environments, leading to fragmented workflows and reduced collaboration across organizational levels. This paper introduces BusiAgent, a novel multi-agent framework leveraging LLMs for advanced decision-making in complex corporate environments. BusiAgent integrates three core innovations: an extended Continuous Time Markov Decision Process (CTMDP) for dynamic agent modeling, a generalized entropy measure to optimize collaborative efficiency, and a multi-level Stackelberg game to handle hierarchical decision processes. Additionally, contextual Thompson sampling is employed for prompt optimization, supported by a comprehensive quality assurance system to mitigate errors. Extensive empirical evaluations across diverse business scenarios validate BusiAgent's efficacy, demonstrating its capacity to generate coherent, client-focused solutions that smoothly integrate granular insights with high-level strategy, significantly outperforming established approaches in both solution quality and user satisfaction. By fusing cutting-edge AI technologies with deep business insights, BusiAgent marks a substantial step forward in AI-driven enterprise decision-making, empowering organizations to navigate complex business landscapes more effectively.△ Less",
    "submitted_date_raw": "Submitted 21 August, 2025; originally announced August 2025.",
    "identity_key": "2508.15447"
  },
  {
    "title": "Mitigating Hallucinations in LM-Based TTS Models via Distribution Alignment Using GFlowNets",
    "abs_url": "https://arxiv.org/abs/2508.15442",
    "pdf_url": "https://arxiv.org/pdf/2508.15442",
    "authors": [
      "Chenlin Liu",
      "Minghui Fang",
      "Patrick Zhang",
      "Wei Zhou",
      "Jie Gao",
      "Jiqing Han"
    ],
    "abstract": "Language Model (LM)-based Text-to-Speech (TTS) systems often generate hallucinated speech that deviates from input text. Existing mitigation strategies either demand excessive training resources or introduce significant inference latency. In this paper, we propose GFlOwNet-guided distribution AlignmenT (GOAT) for LM-based TTS, a post-training framework that mitigates hallucinations without relying on massive resources or inference cost. Specifically, we first conduct an uncertainty analysis, revealing a strong positive correlation between hallucination and model uncertainty. Based on this, we reformulate TTS generation as a trajectory flow optimization problem and introduce an enhanced Subtrajectory Balance objective together with a sharpened internal reward as target distribution. We further integrate reward temperature decay and learning rate optimization for stability and performance balance. Extensive experiments show that GOAT reduce over 50% character error rates on challenging test cases and lowering uncertainty by up to 58%, demonstrating its strong generalization ability and effectiveness.△ Less",
    "submitted_date_raw": "Submitted 21 August, 2025; originally announced August 2025.",
    "identity_key": "2508.15442"
  },
  {
    "title": "Test-time Corpus Feedback: From Retrieval to RAG",
    "abs_url": "https://arxiv.org/abs/2508.15437",
    "pdf_url": "https://arxiv.org/pdf/2508.15437",
    "authors": [
      "Mandeep Rathee",
      "Venktesh V",
      "Sean MacAvaney",
      "Avishek Anand"
    ],
    "abstract": "Retrieval-Augmented Generation (RAG) has emerged as a standard framework for knowledge-intensive NLP tasks, combining large language models (LLMs) with document retrieval from external corpora. Despite its widespread use, most RAG pipelines continue to treat retrieval and reasoning as isolated components, retrieving documents once and then generating answers without further interaction. This static design often limits performance on complex tasks that require iterative evidence gathering or high-precision retrieval. Recent work in both the information retrieval (IR) and NLP communities has begun to close this gap by introducing adaptive retrieval and ranking methods that incorporate feedback. In this survey, we present a structured overview of advanced retrieval and ranking mechanisms that integrate such feedback. We categorize feedback signals based on their source and role in improving the query, retrieved context, or document pool. By consolidating these developments, we aim to bridge IR and NLP perspectives and highlight retrieval as a dynamic, learnable component of end-to-end RAG systems.△ Less",
    "submitted_date_raw": "Submitted 21 August, 2025; originally announced August 2025.",
    "identity_key": "2508.15437"
  },
  {
    "title": "GraSP: A Unified Graph-Based Framework for Scalable Generation, Quality Tagging, and Management of Synthetic Data for SFT and DPO",
    "abs_url": "https://arxiv.org/abs/2508.15432",
    "pdf_url": "https://arxiv.org/pdf/2508.15432",
    "authors": [
      "Bidyapati Pradhan",
      "Surajit Dasgupta",
      "Amit Kumar Saha",
      "Omkar Anustoop",
      "Sriram Puttagunta",
      "Vipul Mittal",
      "Gopal Sarda"
    ],
    "abstract": "The advancement of large language models (LLMs) is critically dependent on the availability of high-quality datasets for Supervised Fine-Tuning (SFT), alignment tasks like Direct Preference Optimization (DPO), etc. In this work, we present a comprehensive synthetic data generation framework that facilitates scalable, configurable, and high-fidelity generation of synthetic data tailored for these training paradigms. Our approach employs a modular and configuration-based pipeline capable of modeling complex dialogue flows with minimal manual intervention. This framework uses a dual-stage quality tagging mechanism, combining heuristic rules and LLM-based evaluations, to automatically filter and score data extracted from OASST-formatted conversations, ensuring the curation of high-quality dialogue samples. The resulting datasets are structured under a flexible schema supporting both SFT and DPO use cases, enabling seamless integration into diverse training workflows. Together, these innovations offer a robust solution for generating and managing synthetic conversational data at scale, significantly reducing the overhead of data preparation in LLM training pipelines.△ Less",
    "submitted_date_raw": "Submitted 21 August, 2025; originally announced August 2025.",
    "identity_key": "2508.15432"
  },
  {
    "title": "An Empirical Study of Knowledge Distillation for Code Understanding Tasks",
    "abs_url": "https://arxiv.org/abs/2508.15423",
    "pdf_url": "https://arxiv.org/pdf/2508.15423",
    "authors": [
      "Ruiqi Wang",
      "Zezhou Yang",
      "Cuiyun Gao",
      "Xin Xia",
      "Qing Liao"
    ],
    "abstract": "Pre-trained language models (PLMs) have emerged as powerful tools for code understanding. However, deploying these PLMs in large-scale applications faces practical challenges due to their computational intensity and inference latency. Knowledge distillation (KD), a promising model compression and acceleration technique, addresses these limitations by transferring knowledge from large teacher models to compact student models, enabling efficient inference while preserving most of the teacher models' capabilities. While this technique has shown remarkable success in natural language processing and computer vision domains, its potential for code understanding tasks remains largely underexplored.\n  In this paper, we systematically investigate the effectiveness and usage of KD in code understanding tasks. Our study encompasses two popular types of KD methods, i.e., logit-based and feature-based KD methods, experimenting across eight student models and two teacher PLMs from different domains on three downstream tasks. The experimental results indicate that KD consistently offers notable performance boosts across student models with different sizes compared with standard fine-tuning. Notably, code-specific PLM demonstrates better effectiveness as the teacher model. Among all KD methods, the latest feature-based KD methods exhibit superior performance, enabling student models to retain up to 98% teacher performance with merely 5% parameters. Regarding student architecture, our experiments reveal that similarity with teacher architecture does not necessarily lead to better performance. We further discuss the efficiency and behaviors in the KD process and inference, summarize the implications of findings, and identify promising future directions.△ Less",
    "submitted_date_raw": "Submitted 21 August, 2025; originally announced August 2025.",
    "identity_key": "2508.15423"
  },
  {
    "title": "LLaSO: A Foundational Framework for Reproducible Research in Large Language and Speech Model",
    "abs_url": "https://arxiv.org/abs/2508.15418",
    "pdf_url": "https://arxiv.org/pdf/2508.15418",
    "authors": [
      "Yirong Sun",
      "Yizhong Geng",
      "Peidong Wei",
      "Yanjun Chen",
      "Jinghan Yang",
      "Rongfei Chen",
      "Wei Zhang",
      "Xiaoyu Shen"
    ],
    "abstract": "The development of Large Speech-Language Models (LSLMs) has been slowed by fragmented architectures and a lack of transparency, hindering the systematic comparison and reproducibility of research. Unlike in the vision-language domain, the LSLM field suffers from the common practice of releasing model weights without their corresponding training data and configurations. To address these critical gaps, we introduce LLaSO, the first fully open, end-to-end framework for large-scale speech-language modeling. LLaSO provides the community with three essential resources: (1) LLaSO-Align, a 12M-instance speech-text alignment corpus; (2) LLaSO-Instruct, a 13.5M-instance multi-task instruction-tuning dataset; and (3) LLaSO-Eval, a reproducible benchmark for standardized evaluation. To validate our framework, we build and release LLaSO-Base, a 3.8B-parameter reference model trained exclusively on our public data. It achieves a normalized score of 0.72, establishing a strong, reproducible baseline that surpasses comparable models. Our analysis reveals that while broader training coverage enhances performance, significant generalization gaps persist on unseen tasks, particularly in pure audio scenarios. By releasing the complete stack of data, benchmarks, and models, LLaSO establishes a foundational open standard to unify research efforts and accelerate community-driven progress in LSLMs. We release the code, dataset, pretrained models, and results in https://github.com/EIT-NLP/LLaSO.△ Less",
    "submitted_date_raw": "Submitted 21 August, 2025; originally announced August 2025.",
    "identity_key": "2508.15418"
  },
  {
    "title": "Bridging Generalization and Personalization in Wearable Human Activity Recognition via On-Device Few-Shot Learning",
    "abs_url": "https://arxiv.org/abs/2508.15413",
    "pdf_url": "https://arxiv.org/pdf/2508.15413",
    "authors": [
      "Pixi Kang",
      "Julian Moosmann",
      "Mengxi Liu",
      "Bo Zhou",
      "Michele Magno",
      "Paul Lukowicz",
      "Sizhen Bian"
    ],
    "abstract": "Human Activity Recognition (HAR) using wearable devices has advanced significantly in recent years, yet its generalization remains limited when models are deployed to new users. This degradation in performance is primarily due to user-induced concept drift (UICD), highlighting the importance of efficient personalization. In this paper, we present a hybrid framework that first generalizes across users and then rapidly adapts to individual users using few-shot learning directly on-device. By updating only the classifier layer with user-specific data, our method achieves robust personalization with minimal computational and memory overhead. We implement this framework on the energy-efficient RISC-V-based GAP9 microcontroller and validate it across three diverse HAR scenarios: RecGym, QVAR-Gesture, and Ultrasound-Gesture. Post-deployment adaptation yields consistent accuracy improvements of 3.73\\%, 17.38\\%, and 3.70\\% respectively. These results confirm that fast, lightweight, and effective personalization is feasible on embedded platforms, paving the way for scalable and user-aware HAR systems in the wild \\footnote{https://github.com/kangpx/onlineTiny2023}.△ Less",
    "submitted_date_raw": "Submitted 21 August, 2025; originally announced August 2025.",
    "identity_key": "2508.15413"
  },
  {
    "title": "When Audio and Text Disagree: Revealing Text Bias in Large Audio-Language Models",
    "abs_url": "https://arxiv.org/abs/2508.15407",
    "pdf_url": "https://arxiv.org/pdf/2508.15407",
    "authors": [
      "Cheng Wang",
      "Gelei Deng",
      "Xianglin Yang",
      "Han Qiu",
      "Tianwei Zhang"
    ],
    "abstract": "Large Audio-Language Models (LALMs) are enhanced with audio perception capabilities, enabling them to effectively process and understand multimodal inputs that combine audio and text. However, their performance in handling conflicting information between audio and text modalities remains largely unexamined. This paper introduces MCR-BENCH, the first comprehensive benchmark specifically designed to evaluate how LALMs prioritize information when presented with inconsistent audio-text pairs. Through extensive evaluation across diverse audio understanding tasks, we reveal a concerning phenomenon: when inconsistencies exist between modalities, LALMs display a significant bias toward textual input, frequently disregarding audio evidence. This tendency leads to substantial performance degradation in audio-centric tasks and raises important reliability concerns for real-world applications. We further investigate the influencing factors of text bias, and explore mitigation strategies through supervised finetuning, and analyze model confidence patterns that reveal persistent overconfidence even with contradictory inputs. These findings underscore the need for improved modality balance during training and more sophisticated fusion mechanisms to enhance the robustness when handling conflicting multi-modal inputs. The project is available at https://github.com/WangCheng0116/MCR-BENCH.△ Less",
    "submitted_date_raw": "Submitted 21 August, 2025; originally announced August 2025.",
    "identity_key": "2508.15407"
  },
  {
    "title": "Hybrid Least Squares/Gradient Descent Methods for DeepONets",
    "abs_url": "https://arxiv.org/abs/2508.15394",
    "pdf_url": "https://arxiv.org/pdf/2508.15394",
    "authors": [
      "Jun Choi",
      "Chang-Ock Lee",
      "Minam Moon"
    ],
    "abstract": "We propose an efficient hybrid least squares/gradient descent method to accelerate DeepONet training. Since the output of DeepONet can be viewed as linear with respect to the last layer parameters of the branch network, these parameters can be optimized using a least squares (LS) solve, and the remaining hidden layer parameters are updated by means of gradient descent form. However, building the LS system for all possible combinations of branch and trunk inputs yields a prohibitively large linear problem that is infeasible to solve directly. To address this issue, our method decomposes the large LS system into two smaller, more manageable subproblems $\\unicode{x2014}$ one for the branch network and one for the trunk network $\\unicode{x2014}$ and solves them separately. This method is generalized to a broader type of $L^2$ loss with a regularization term for the last layer parameters, including the case of unsupervised learning with physics-informed loss.△ Less",
    "submitted_date_raw": "Submitted 21 August, 2025; originally announced August 2025.",
    "identity_key": "2508.15394"
  },
  {
    "title": "Bladder Cancer Diagnosis with Deep Learning: A Multi-Task Framework and Online Platform",
    "abs_url": "https://arxiv.org/abs/2508.15379",
    "pdf_url": "https://arxiv.org/pdf/2508.15379",
    "authors": [
      "Jinliang Yu",
      "Mingduo Xie",
      "Yue Wang",
      "Tianfan Fu",
      "Xianglai Xu",
      "Jiajun Wang"
    ],
    "abstract": "Clinical cystoscopy, the current standard for bladder cancer diagnosis, suffers from significant reliance on physician expertise, leading to variability and subjectivity in diagnostic outcomes. There is an urgent need for objective, accurate, and efficient computational approaches to improve bladder cancer diagnostics.\n  Leveraging recent advancements in deep learning, this study proposes an integrated multi-task deep learning framework specifically designed for bladder cancer diagnosis from cystoscopic images. Our framework includes a robust classification model using EfficientNet-B0 enhanced with Convolutional Block Attention Module (CBAM), an advanced segmentation model based on ResNet34-UNet++ architecture with self-attention mechanisms and attention gating, and molecular subtyping using ConvNeXt-Tiny to classify molecular markers such as HER-2 and Ki-67. Additionally, we introduce a Gradio-based online diagnostic platform integrating all developed models, providing intuitive features including multi-format image uploads, bilingual interfaces, and dynamic threshold adjustments.\n  Extensive experimentation demonstrates the effectiveness of our methods, achieving outstanding accuracy (93.28%), F1-score (82.05%), and AUC (96.41%) for classification tasks, and exceptional segmentation performance indicated by a Dice coefficient of 0.9091. The online platform significantly improved the accuracy, efficiency, and accessibility of clinical bladder cancer diagnostics, enabling practical and user-friendly deployment. The code is publicly available.\n  Our multi-task framework and integrated online tool collectively advance the field of intelligent bladder cancer diagnosis by improving clinical reliability, supporting early tumor detection, and enabling real-time diagnostic feedback. These contributions mark a significant step toward AI-assisted decision-making in urology.△ Less",
    "submitted_date_raw": "Submitted 21 August, 2025; originally announced August 2025.",
    "identity_key": "2508.15379"
  }
]